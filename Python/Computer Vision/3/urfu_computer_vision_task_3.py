# -*- coding: utf-8 -*-
"""UrFU_Computer_Vision_Task_3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/13KBqT6JHYQtJjyzxnJTjIOD28p782cox

# Задание, которое в форме для ДЗ - настроить архитектуру и гипер-параметры нейронной сети так, чтобы достичь максимальной точности на аугментированной тестовой выборке.

---

1. Import Packages
---
"""

import matplotlib.pyplot as plt
import numpy as np
from sklearn import datasets, metrics
from sklearn.model_selection import train_test_split
from tensorflow import keras
from tensorflow.keras import layers
from keras.models import load_model

"""2. Load Datasets

---
"""

num_classes = 10

def load_dataset_8x8():
  digits = datasets.load_digits()
  x_train, x_test, y_train, y_test = train_test_split(digits.images, digits.target, test_size = 0.3, shuffle = True)
  return x_train, y_train, x_test, y_test

def load_dataset_28x28():
  (x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()
  return x_train, y_train, x_test, y_test

"""3. Data Preparation

---
"""

x_train, y_train, x_test, y_test = load_dataset_28x28()

x_train = x_train.astype("float32") / 255
x_test  = x_test.astype("float32") / 255

x_train = np.expand_dims(x_train, -1)
x_test = np.expand_dims(x_test, -1)

y_train = keras.utils.to_categorical(y_train, num_classes)
y_test = keras.utils.to_categorical(y_test, num_classes)

input_shape = (x_train.shape[1:])

print('Image shape:', input_shape)
print('X:', x_train.shape, x_test.shape)
print('Y:', y_train.shape, y_test.shape)

"""4. CNN Model

---
"""

model = keras.Sequential(
    [
        keras.layers.InputLayer(input_shape=(input_shape)),
        layers.Conv2D(32, kernel_size=(3, 3), activation="relu"),
        layers.MaxPooling2D(pool_size=(2, 2)),
        layers.Conv2D(64, kernel_size=(2, 2), activation="relu"),
        layers.MaxPooling2D(pool_size=(2, 2)),
        layers.Flatten(),
        layers.Dense(num_classes, activation="softmax"),
    ]
)


model.compile(loss="categorical_crossentropy", optimizer="adam", metrics=["accuracy"])

model.summary()

keras.utils.plot_model(model, show_shapes=True, show_layer_names=False)

"""# 5. Training without Augmentation

## 5.1. Training
"""

batch_size = 64
epochs = 30

history = model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.3)

"""## 5.2. Show Training Process"""

fig, ax = plt.subplots(1, 2, figsize = (20, 10));

ax[0].plot(history.history['loss']);
ax[0].plot(history.history['val_loss']);
ax[0].set_ylabel('loss');

ax[1].plot(history.history['accuracy']);
ax[1].plot(history.history['val_accuracy']);
ax[1].set_ylabel('accuracy');

for a in ax:
  a.set_xlabel('epoch');
  a.legend(['train', 'val'], loc='upper right');
  a.grid();

"""# 5.3. Print Classification Metrics"""

y_train_hat = model.predict(x_train).argmax(axis=-1);
y_train_ = y_train.argmax(axis=-1); # need to change format for applying sklearn classification_report()

y_test_hat = model.predict(x_test).argmax(axis=-1);
y_test_ = y_test.argmax(axis=-1); # need to change format for applying sklearn classification_report()

print("Classification report:\n{}\n".format(metrics.classification_report(y_train_, y_train_hat)));
print("Classification report:\n{}\n".format(metrics.classification_report(y_test_, y_test_hat)));

print("Confusion matrix");

fig, ax = plt.subplots(figsize=(10, 10));
disp = metrics.ConfusionMatrixDisplay(confusion_matrix=metrics.confusion_matrix(y_test_, y_test_hat), display_labels=np.arange(num_classes));
disp.plot(ax = ax);
pass

"""# 6. AUGMENTATION

## 6.1. Import Additional Packages
"""

# Commented out IPython magic to ensure Python compatibility.
import cv2 as cv
from google.colab.patches import cv2_imshow # for image display

# %pip install mpld3
import matplotlib.pyplot as plt
import mpld3
from mpld3 import plugins

def show_mpld3_images(images, figsize=(16, 8)):
  fig, ax = plt.subplots(1, len(images), figsize=figsize)

  if len(images) == 1:
    ax = [ax] # need to consider ax as iterable object

  for a, image in zip(ax, images):
    if image.ndim == 2 or (image.ndim == 3 and image.shape[2] == 1): # grayscale
      a.imshow(image.reshape(image.shape[0:2]), cmap='gray', vmin=0, vmax=255)
    else:
      a.imshow(image)

  return mpld3.display()

show_mpld3_images([x_test[1] * 255])

"""## 6.2. Visualization of Augmentation Techniques and Testing the Model"""

# decrease brightness
x_test_new = x_test * 0.3
show_mpld3_images([x_test[0] * 255, x_test_new[0] * 255])

y_test_hat = model.predict(x_test_new).argmax(axis=-1)
print("Classification report:\n{}\n".format(metrics.classification_report(y_test_, y_test_hat)))

# increase brightness
x_test_new = x_test * 1.7
show_mpld3_images([x_test[0] * 255, x_test_new[0] * 255])

y_test_hat = model.predict(x_test_new).argmax(axis=-1)
print("Classification report:\n{}\n".format(metrics.classification_report(y_test_, y_test_hat)))

# gaussian noise
x_test_new = x_test + np.random.normal(0, 0.2, x_test.shape)
show_mpld3_images([x_test[0] * 255, x_test_new[0] * 255])

y_test_hat = model.predict(x_test_new).argmax(axis=-1)
print("Classification report:\n{}\n".format(metrics.classification_report(y_test_, y_test_hat)))

# salt & pepper
salt_and_pepper = np.random.rand(x_test.shape[0], x_test.shape[1], x_test.shape[2], x_test.shape[3])
x_test_new = x_test.copy()
x_test_new[salt_and_pepper > 0.95] = 1 # salt
x_test_new[salt_and_pepper < 0.05] = 0 # papper
show_mpld3_images([x_test[0] * 255, x_test_new[0] * 255])

y_test_hat = model.predict(x_test_new).argmax(axis=-1)
print("Classification report:\n{}\n".format(metrics.classification_report(y_test_, y_test_hat)))

# translation
x_test_new = x_test.copy()

shift_matrix = np.float32([[1, 0, 2], [0, 1, 2]])

for i, image in enumerate(x_test_new):
  x_test_new[i] = np.expand_dims(cv.warpAffine(image, shift_matrix, (image.shape[1], image.shape[0])), -1)

show_mpld3_images([x_test[0] * 255, x_test_new[0] * 255])

y_test_hat = model.predict(x_test_new).argmax(axis=-1)
print("Classification report:\n{}\n".format(metrics.classification_report(y_test_, y_test_hat)))

# rotation
x_test_new = x_test.copy()

rows, cols = x_test.shape[1:3]
rot_center = ((cols-1) / 2.0, (rows-1) / 2.0)
rot_matrix = cv.getRotationMatrix2D(rot_center, 30, 1)

for i, image in enumerate(x_test_new):
  x_test_new[i] = np.expand_dims(cv.warpAffine(image, rot_matrix, (cols,rows)), -1)

show_mpld3_images([x_test[0] * 255, x_test_new[0] * 255])

y_test_hat = model.predict(x_test_new).argmax(axis=-1)
print("Classification report:\n{}\n".format(metrics.classification_report(y_test_, y_test_hat)))

"""## 6.3. Creation Single Augmented Dataset"""

x_train_aug = x_train.copy()
x_test_aug = x_test.copy()

y_train_aug = y_train.copy()
y_test_aug = y_test.copy()

def add_ds(x_aug, x_new, y_aug, y):
  x_aug = np.append(x_aug, x_new, axis = 0)
  y_aug = np.append(y_aug, y, axis = 0)
  return x_aug, y_aug

def augment_dataset(x, y):
  x_aug = x.copy()
  y_aug = y.copy()

  # brightness -
  x_aug, y_aug = add_ds(x_aug, x * 0.3, y_aug, y)

  # brightness +
  x_aug, y_aug = add_ds(x_aug, x * 1.7, y_aug, y)

  # gaussian noise
  x_aug, y_aug = add_ds(x_aug, (x + np.random.normal(0, 0.1, x.shape)), y_aug, y)

  # salt & paper
  salt_and_pepper = np.random.rand(x.shape[0], x.shape[1], x.shape[2], x.shape[3])
  x_new = x.copy()
  x_new[salt_and_pepper > 0.95] = 1
  x_new[salt_and_pepper < 0.05] = 0
  x_aug, y_aug = add_ds(x_aug, x_new, y_aug, y)

  # translation
  x_new = x.copy()
  shift_matrix = np.float32([[1, 0, 2], [0, 1, 2]])

  for i, image in enumerate(x):
    x_new[i] = np.expand_dims(cv.warpAffine(image, shift_matrix, (image.shape[1], image.shape[0])), -1)

  x_aug, y_aug = add_ds(x_aug, x_new, y_aug, y)

  # rotation
  x_new = x.copy()
  rows, cols = x.shape[1:3]
  rot_center = ((cols-1) / 2.0, (rows-1) / 2.0)
  rot_matrix = cv.getRotationMatrix2D(rot_center, 30, 1)

  for i, image in enumerate(x):
    x_new[i] = np.expand_dims(cv.warpAffine(image, rot_matrix, (cols,rows)), -1)

  x_aug, y_aug = add_ds(x_aug, x_new, y_aug, y)

  return x_aug, y_aug

x_train_aug, y_train_aug = augment_dataset(x_train, y_train)
x_test_aug, y_test_aug = augment_dataset(x_test, y_test)

print(x_train_aug.shape, x_test_aug.shape)
print(y_train_aug.shape, y_test_aug.shape)

show_mpld3_images([x_train_aug[0] * 255, x_train_aug[1*60000] * 255])

y_test_hat = model.predict(x_test_aug).argmax(axis=-1)
y_test_aug_ = y_test_aug.argmax(axis=-1)

print("Classification report:\n{}\n".format(metrics.classification_report(y_test_aug_, y_test_hat)))

print("Confusion matrix")

fig, ax = plt.subplots(figsize=(10, 10))
disp = metrics.ConfusionMatrixDisplay(confusion_matrix=metrics.confusion_matrix(y_test_aug_, y_test_hat), display_labels=np.arange(num_classes))
disp.plot(ax = ax)
pass

"""# 7. Training with Augmentation"""

model = keras.Sequential(
    [
        keras.layers.InputLayer(input_shape=(input_shape)),
        layers.Conv2D(32, kernel_size=(3, 3), activation="relu"),
        layers.MaxPooling2D(pool_size=(2, 2)),
        layers.Conv2D(64, kernel_size=(2, 2), activation="relu"),
        layers.MaxPooling2D(pool_size=(2, 2)),
        layers.Conv2D(64, kernel_size=(2, 2), activation="relu"),
        layers.MaxPooling2D(pool_size=(2, 2)),
        layers.Flatten(),
        layers.Dropout(0.5),
        layers.Dense(num_classes, activation="softmax"),
    ]
)

model.compile(loss="categorical_crossentropy", optimizer="adam", metrics=["accuracy"])

model.summary()

keras.utils.plot_model(model, show_shapes=True, show_layer_names=False)

batch_size = 64*7
epochs = 30

history = model.fit(x_train_aug, y_train_aug, batch_size=batch_size, epochs=epochs, validation_split=0.3)

fig, ax = plt.subplots(1, 2, figsize = (20, 10))

ax[0].plot(history.history['loss'])
ax[0].plot(history.history['val_loss'])
ax[0].set_ylabel('loss')

ax[1].plot(history.history['accuracy'])
ax[1].plot(history.history['val_accuracy'])
ax[1].set_ylabel('accuracy')

for a in ax:
  a.set_xlabel('epoch')
  a.legend(['train', 'val'], loc='upper right')
  a.grid()

y_test_hat = model.predict(x_test_aug).argmax(axis=-1)
y_test_aug_ = y_test_aug.argmax(axis=-1)

print("Classification report:\n{}\n".format(metrics.classification_report(y_test_aug_, y_test_hat)))

print("Confusion matrix")

fig, ax = plt.subplots(figsize=(10, 10))
disp = metrics.ConfusionMatrixDisplay(confusion_matrix=metrics.confusion_matrix(y_test_aug_, y_test_hat), display_labels=np.arange(num_classes))
disp.plot(ax = ax)
pass

"""# 8. Saving the Model

# 8.1. Saving
"""

model.save('model.h5')

"""# 8.2. Testing"""

loaded_model = load_model('model.h5')

y_test_hat = loaded_model.predict(x_test_aug).argmax(axis=-1)
y_test_ = y_test.argmax(axis=-1)

print("Classification report:\n{}\n".format(metrics.classification_report(y_test_aug_, y_test_hat)))