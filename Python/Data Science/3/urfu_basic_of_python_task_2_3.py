# -*- coding: utf-8 -*-
"""UrFU_Basic_Of_Python_Task_2_3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1bKFthRvmbrn_F1cvJVo2v0WUX0-L-7DH

# 1. Задание, которое в форме для ДЗ - из исходной таблицы требуется удалить строки данных, содержащие попуски, NaN, прочерки и т.д. Столбец Date разделить на три столбца (день, месяц, год), аналогично поступить со столбцом Time (минуты, секунды). Данные в столбце wind_speed_2 оставить только в м/с. В остальных столбцах оставить только числовые данные без лишних символов.

---

После выполнения работы был замечены некоторые недостатки исходной таблицы:

1. Показания влажности отрицательные;
2. В некоторых ячейках отсутсвует показание в м/с;
3. Была другая задача с исходной таблицей (в задании надо было разделить два стоблца Date и Time, а в таблице всё находилось в столбце Date);
4. При загрузки таблицы в Colab проценты перевелись в числовое соотношение процента от 0 до 1.

Данные недостатки были учтены в данном коде.

---
"""

# Для использования данных из Drive
from google.colab import drive

#Для работы с данными
import pandas as pd
import numpy as np

#Для визуализации
import matplotlib.pyplot as plt
import seaborn as sn

#Для моделей регрессии
from sklearn.linear_model import LinearRegression

from sklearn.preprocessing import PolynomialFeatures as poly
from sklearn.pipeline import Pipeline
from sklearn.neighbors import KNeighborsRegressor

#Для разделения данных на выборки
from sklearn.model_selection import cross_val_score, train_test_split
from sklearn.model_selection import cross_validate
from sklearn.model_selection import ShuffleSplit

#Для оценивания прогноза (метрики точности)
import sklearn.metrics
from sklearn.metrics import mean_squared_error as mse
from sklearn.metrics import r2_score
from sklearn.metrics import mean_absolute_error as mae
from sklearn.metrics import max_error

#PATH = '/content/drive/MyDrive/Colab Notebooks/s10.xlsx';
#drive.mount('/content/drive');

PATH = '/content/s10.xlsx';

def clear_data(path):

  rew_data = pd.read_excel(path, na_values=['?', '-', ' ', '_', '–',], header = 0);

  data = rew_data.copy();

  data[['DMY', 'HM']] = data['Date'].str.split(' ', 1, expand = True);

  data['Day'] = data['DMY'].str.split('.', expand = True)[0];
  data['Month'] = data['DMY'].str.split('.', expand = True)[1];
  data['Year'] = data['DMY'].str.split('.', expand = True)[2];

  data['Hour'] = data['HM'].str.split(':', expand=True)[0];
  data['Minute'] = data['HM'].str.split(':', expand=True)[1];

  data['Wind_speed'] = data['Wind_speed'].str.split('/', expand = True)[2];

  date = data.replace(['?', '-', ' ', '  ', '   ', '_', '–'], np.nan, inplace = True);
  data = data.dropna(axis=0);

  data = data.replace("[^\d\.]", "", regex = True);

  data["Humidity"] = abs(data.Humidity.astype(float) * 100);

  data = data.drop(labels = ['DMY' ,'HM'], axis=1);

  data_cleared = data.reindex(columns=['Day', 'Month', 'Year', 'Hour', 'Minute',
                                       'Day_number', 'Temp', 'Temp_2', 'Humidity', 'Visibility',
                                       'Lightness', 'Wind_speed',  'Solar_ang_1']);

  convert_dict = {"Day": int, "Month": int, "Year": int, "Hour": int, "Minute": int, "Day_number": int,
                  "Temp": float, "Temp_2": float, "Humidity": float, "Visibility": float, "Lightness": float, "Wind_speed": float, "Solar_ang_1": float};
  data_cleared = data_cleared.astype(convert_dict);

  data_cleared.to_excel('/content/s10_cleared_with_old_index.xlsx');

  data_cleared = data_cleared.reset_index(drop = True);
  data_cleared.to_excel('/content/s10_cleared_with_new_index.xlsx');

  data_cleared.to_excel('/content/s10_cleared_without_index.xlsx', index = False);

  print(f'\tФорматы в таблице:\n{data_cleared.dtypes}\n');

  return data_cleared;

print(f'\tРезультат фильтрации входных данных: \n{clear_data(PATH)}\n')

"""
#2. Задание, которое в форме для ДЗ - к очищенным данным применить базовые модели регресии, которые были рассмотрены на занятии (линейная и полиномиальная регрессия, метод ближайших соседей). Предварительно данные разделить на массивы признаков и целевой переменной, выделить обучающую и тестовую выборки. Изменяя входные параметры (степень полинома, число соседей, соотношение обучающей и тестовой выборок и т.д), убедиться в изменении получаемого прогноза (изменении его метрик точности).
---
"""

#drive.mount('/content/drive');
#PATH = '/content/drive/MyDrive/Colab Notebooks/s10_cleared_without_index.xlsx';
PATH = '/content/s10_cleared_without_index.xlsx';
test_data = pd.read_excel(PATH);
data = pd.DataFrame(data = test_data);

for column in data:
  plt.figure(figsize = (20,10));
  sn.scatterplot(y = data[column], x = data.index, color = 'red');
  sn.lineplot(y = data[column], x = data.index, color = 'green');
  plt.xlabel('Observation', fontsize = 15);
  plt.ylabel(column, fontsize = 15);

plt.figure(figsize = (10, 10));
sn.heatmap(data.corr(), cmap = 'RdYlGn', vmax = 1, vmin = -1, annot = True);

print(data.columns);

TARGET_TRAIN = 'Solar_ang_1';
TEST_SIZE = 0.10;
TARGET_DELETE = ['Day', 'Month', 'Year', 'Hour', 'Minute', 'Day_number'];

X = data.drop([TARGET_TRAIN], axis = 1);
y = data[TARGET_TRAIN];

X_train, X_test, y_train, y_test  =  train_test_split(X,y, test_size  =  TEST_SIZE);
print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)

y_test.to_excel('/content/y_test.xlsx');
X_test.to_excel('/content/X_test.xlsx');
X_train = X_train.drop(TARGET_DELETE, axis = 1);
X_test = X_test.drop(TARGET_DELETE, axis = 1);

N_SPLITS_DEFAULT = 10;
DEGREE_DEFAULT =  2;
N_NEIGHBORS_DEFAULT = 4;

"""# 1. Модель линейной регрессии"""

N_SPLITS_LINE = 0;

if N_SPLITS_LINE <= 0: N_SPLITS_LINE = N_SPLITS_DEFAULT;

lin_reg = LinearRegression();
lin_reg.fit(X_train, y_train);
scoring   =  {'R2': 'r2',
           '-MSE': 'neg_mean_squared_error',
           '-MAE': 'neg_mean_absolute_error',
           'Max': 'max_error'};
scores = cross_validate(lin_reg, X_train, y_train, scoring = scoring, cv = ShuffleSplit(n_splits = N_SPLITS_LINE));
y_pred = lin_reg.predict(X_test);

print('Cross-Validation errors');
DF_reg  =  pd.DataFrame(scores);
display(DF_reg);

print('Test errors');
print('Mean squared error on test_set: %.4f' % mse(y_test,y_pred));
print('R2  on test_set: %.4f' %  r2_score(y_test,y_pred));

"""# 2. Модель полиномиальной регрессии"""

N_SPLITS_PINE = 0;
DEGREE_PINE = 0;

if N_SPLITS_PINE <= 0: N_SPLITS_PINE = N_SPLITS_DEFAULT;
if DEGREE_PINE <= 1: DEGREE_PINE = DEGREE_DEFAULT;

PF  =  poly(degree = DEGREE_PINE, include_bias = True, interaction_only = False);
#Rid = Ridge(alpha = 0.1);
LR = LinearRegression();
pipe = Pipeline([('polynomial_features', PF), ('lr', LR)])
pipe.fit(X_train, y_train);
scoring_pipe   =  {'R2': 'r2',
           '-MSE': 'neg_mean_squared_error',
           '-MAE': 'neg_mean_absolute_error',
           'Max': 'max_error'};
scores_pipe = cross_validate(pipe, X_train, y_train, scoring = scoring_pipe, cv = ShuffleSplit(n_splits = N_SPLITS_PINE));
y_pred_pipe = pipe.predict(X_test);

print('Cross-Validation error');
DF_reg_pipe  =  pd.DataFrame(scores_pipe);
display(DF_reg_pipe);

print('Test errors');
print('Mean squared error on test_set: %.4f' % mse(y_test,y_pred_pipe));
print('R2  on test_set: %.4f' %  r2_score(y_test,y_pred_pipe));

"""# 3.Модель ближайших соседей (KNN)"""

N_NEIGHBORS_KNN = 0;
N_SPLITS_KNN = 0;

if N_SPLITS_KNN <=  0: N_SPLITS_KNN = N_SPLITS_DEFAULT;
if N_NEIGHBORS_KNN <=  0: N_NEIGHBORS_KNN = N_NEIGHBORS_DEFAULT;

k_reg  =  KNeighborsRegressor(n_neighbors = N_NEIGHBORS_KNN, weights = 'distance');
k_reg.fit(X_train, y_train);
scoring_k   =  {'R2': 'r2',
           '-MSE': 'neg_mean_squared_error',
           '-MAE': 'neg_mean_absolute_error',
           'Max': 'max_error'};
scores_k = cross_validate(k_reg, X_train, y_train, scoring = scoring_k, cv = ShuffleSplit(n_splits = N_SPLITS_KNN));
y_pred_k = k_reg.predict(X_test);

print('Cross-Validation error');
DF_reg_k = pd.DataFrame(scores_k);
display(DF_reg_k);

print('Test errors');
print('Mean squared error on test_set: %.4f' % mse(y_test,y_pred_k));
print('R2  on test_set: %.4f' %  r2_score(y_test,y_pred_k));

x = np.linspace(0, X_test.shape[0], X_test.shape[0]);
plt.figure(figsize = (50,25));
plt.subplot(421);
plt.title('Модели регрессий', fontsize = 15);
plt.scatter(x, y_pred, c = 'r');
plt.scatter(x, y_pred_pipe, c = 'y');
plt.scatter(x, y_pred_k, c = 'b');
plt.scatter(x, y_test, c = 'g');
plt.plot(x, y_pred, '-r', linewidth = 3, label = 'Линейная регрессия');
plt.plot(x, y_pred_pipe, '-y', linewidth = 3, label = 'Полиноминальная регрессия');
plt.plot(x, y_pred_k, '-b', linewidth = 3, label = 'Модель ближайших соседей');
plt.plot(x, y_test, 'g--', linewidth = 3, label = 'Фактические данные');
plt.legend(fontsize = 15);
plt.xlabel('Observations', fontsize = 15);
plt.ylabel(TARGET_TRAIN, fontsize = 15);
plt.subplot(422);
plt.title('Модели регрессий', fontsize = 15);
plt.plot(y_test, y_test, '-g', linewidth = 2, label = 'Actual');
plt.scatter(y_test, y_pred, label = 'Линейная регрессия', c = 'r');
plt.scatter(y_test, y_pred_pipe, label = 'Полиноминальная регрессия', c = 'y');
plt.scatter(y_test, y_pred_k, label =  'Модель ближайших соседей', c = 'b');
plt.legend(fontsize = 15);
plt.xlabel('Actual', fontsize = 15);
plt.ylabel('Forecasted', fontsize = 15);

plt.subplot(423);
plt.title('Модель линейной регрессии', fontsize = 15);
plt.scatter(x, y_pred, c = 'r');
plt.scatter(x, y_test, c = 'g');
plt.plot(x, y_pred, '-r', linewidth = 3, label = 'Forecast');
plt.plot(x, y_test, 'g--', linewidth = 3, label = 'Actual');
plt.legend(fontsize = 15);
plt.xlabel('Observations', fontsize = 15);
plt.ylabel(TARGET_TRAIN, fontsize = 15);
plt.subplot(424);
plt.title('Модель линейной регрессии', fontsize = 15);
plt.plot(y_test, y_test, '-g', linewidth = 2, label = 'Actual');
plt.scatter(y_test, y_pred, label = 'Forecast', c = 'r');
plt.legend(fontsize = 15);
plt.xlabel('Actual', fontsize = 15);
plt.ylabel('Forecasted', fontsize = 15);

plt.subplot(425);
plt.title('Модель полиноминальной регрессии', fontsize = 15);
plt.scatter(x, y_pred_pipe, c = 'y');
plt.scatter(x, y_test, c = 'g');
plt.plot(x, y_pred_pipe, '-y', linewidth = 3, label = 'Forecast');
plt.plot(x, y_test, 'g--', linewidth = 3, label = 'Actual');
plt.legend(fontsize = 15);
plt.xlabel('Observations', fontsize = 15);
plt.ylabel(TARGET_TRAIN, fontsize = 15);
plt.subplot(426);
plt.title('Модель полиноминальной регрессии', fontsize = 15);
plt.plot(y_test, y_test, '-g', linewidth = 2, label = 'Actual');
plt.scatter(y_test, y_pred_pipe, label = 'Forecast', c = 'y');
plt.legend(fontsize = 15);
plt.xlabel('Actual', fontsize = 15);
plt.ylabel('Forecasted', fontsize = 15);

plt.subplot(427);
plt.title('Модель ближайших соседей', fontsize = 15);
plt.scatter(x, y_pred_k, c = 'b');
plt.scatter(x, y_test, c = 'g');
plt.plot(x, y_pred_k, '-b', linewidth = 3, label = 'Forecast');
plt.plot(x, y_test, 'g--', linewidth = 3, label = 'Actual');
plt.legend(fontsize = 15);
plt.xlabel('Observations', fontsize = 15);
plt.ylabel(TARGET_TRAIN, fontsize = 15);
plt.subplot(428);
plt.title('Модель ближайших соседей', fontsize = 15);
plt.plot(y_test, y_test, '-g', linewidth = 2, label = 'Actual');
plt.scatter(y_test, y_pred_k, label = 'Forecast', c = 'b');
plt.legend(fontsize = 15);
plt.xlabel('Actual', fontsize = 15);
plt.ylabel('Forecasted', fontsize = 15);
plt.savefig('saved_figure.png');
plt.show();

"""plt.figure(figsize = (10, 10));
sn.heatmap(data.corr(), cmap = 'RdYlGn', vmax = 1, vmin = -1, annot = True);
"""